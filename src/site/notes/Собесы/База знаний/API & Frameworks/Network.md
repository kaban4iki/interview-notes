---
{"dg-publish":true,"permalink":"/sobesy/baza-znanij/api-and-frameworks/network/"}
---

## HTTP как транспорт

**Кратко:**  
HTTP — это транспортный протокол запрос–ответ.  

**Типовой вопрос:**  
Почему HTTP плохо подходит для долгоживущих соединений?

**Ответ:**  
HTTP (даже HTTP/2):
- ориентирован на request/response
- не держит состояние
- плохо масштабируется для real-time

Для real-time используют WebSockets или SSE.

---

## HTTP/1.1 vs HTTP/2 vs HTTP/3

**Кратко:**  
Развитие HTTP направлено на снижение задержек и более эффективное использование сетевого соединения при большом количестве параллельных запросов.

**Типовой вопрос:**  
В чём практическая разница между HTTP/1.1, HTTP/2 и HTTP/3?

**Ответ:**  
**HTTP/1.1:**
- один запрос за раз в рамках соединения
- требуется много TCP-соединений
- высокая задержка при большом числе запросов

**HTTP/2:**
- multiplexing: несколько запросов параллельно в одном соединении
- сжатие заголовков
- меньше накладных расходов на соединения

Но:
- работает поверх TCP
- потеря одного пакета может замедлить все запросы в соединении

**HTTP/3:**
- построен поверх QUIC (UDP)
- потеря пакета влияет только на конкретный поток
- лучше работает в сетях с нестабильным соединением


---

## TCP vs UDP

**Кратко:**  
TCP — надёжность.  
UDP — скорость и контроль.

**Типовой вопрос:**  
Почему HTTP/3 использует UDP?

**Ответ:**  
UDP позволяет:
- управлять retransmission
- избегать head-of-line blocking
- быстрее восстанавливать соединение

Надёжность реализуется на уровне QUIC, а не TCP.

---

## QUIC

**Кратко:**  
QUIC — транспорт поверх UDP с TLS по умолчанию.

**Типовой вопрос:**  
Почему QUIC важен для мобильных клиентов?

**Ответ:**  
QUIC:
- быстрее восстанавливает соединение
- лучше работает при смене сети (Wi-Fi → LTE)
- снижает latency

QUIC = основа HTTP/3.

---

## REST (Representational State Transfer)

**Кратко:**  
REST — это архитектурный стиль проектирования сетевых API, описывающий **как взаимодействуют клиент и сервер**, а не конкретный формат данных или протокол.  
REST почти всегда реализуется поверх HTTP, но логически от него не зависит.

**Типовой вопрос:**  
Что на самом деле означает REST и почему большинство REST API не являются RESTful?

**Ответ:**  
REST определяет набор ограничений:
- клиент–серверная модель (разделение ответственности)
- отсутствие состояния (stateless)
- использование стандартных HTTP-методов (`GET`, `POST`, `PUT`, `DELETE`)
- однозначное использование HTTP status codes
- работа с **ресурсами**, а не действиями

На практике большинство API:
- используют HTTP и JSON
- но реализуют RPC-подобные вызовы
- частично или полностью игнорируют ограничения REST

---

## HATEOAS

**HATEOAS** — принцип REST, при котором сервер возвращает не только данные, но и **ссылки на возможные дальнейшие действия**.

```json
{
  "id": 42,
  "status": "active",
  "links": {
    "self": "/users/42",
    "deactivate": "/users/42/deactivate"
  }
}
```

---

## SOAP (Simple Object Access Protocol)

**Кратко:**  
SOAP — это строгий протокол обмена сообщениями, основанный на XML и формальных контрактах.  
Используется в enterprise и легаси-системах.

**Типовой вопрос:**  
Почему SOAP считают устаревшим и почему он всё ещё используется?

**Ответ:**  
SOAP характеризуется:
- строгим контрактом (WSDL)
- обязательным XML
- встроенной поддержкой безопасности, транзакций и расширений
- формализованными ошибками

Минусы:
- высокая сложность
- многословность XML
- трудность отладки и развития

Плюсы:
- стабильность
- строгая спецификация
- востребован в банковских и корпоративных системах

---

## RPC поверх HTTP

**Кратко:**  
RPC поверх HTTP — это подход, при котором HTTP используется **как транспорт**, а само API моделируется как вызов методов, а не как работа с ресурсами.  
Формально это не REST, но это самый распространённый стиль API в продакшене.

**Типовой вопрос:**  
Чем RPC-подход поверх HTTP отличается от REST и почему его сознательно выбирают?

**Ответ:**  
RPC API:
- описывает **действия**, а не ресурсы (`/createUser`, `/calculatePrice`)
- использует HTTP в основном как транспорт
- часто возвращает `200 OK` с бизнес-статусом в теле

Почему это выбирают:
- проще и понятнее для клиентов
- легче отражает бизнес-операции
- проще эволюционировать сложные сценарии

Минусы:
- слабее используется HTTP семантика
- хуже работает кэширование
- меньше стандартизации

---

## gRPC

**Кратко:**  
gRPC — это высокопроизводительный RPC-фреймворк, использующий:
- HTTP/2 как транспорт
- Protocol Buffers как контракт
- строгую типизацию и кодогенерацию

**Типовой вопрос:**  
В каких случаях gRPC даёт реальное преимущество по сравнению с HTTP+JSON?

**Ответ:**  
gRPC эффективен, когда:
- есть множество внутренних сервисов
- важны latency и пропускная способность
- нужен строгий контракт между командами

Преимущества:
- бинарный формат (меньше трафика)
- streaming (client / server / bidirectional)
- автоматическая генерация клиентов

Ограничения:
- сложен для браузеров
- требует поддержки protobuf
- тяжелее дебажить без tooling

gRPC — стандарт для internal service-to-service, но редко используется как public API.

---

## WebSockets

**Кратко:**  
WebSockets — это протокол для постоянного двустороннего соединения поверх одного TCP-коннекта.

**Типовой вопрос:**  
Какие архитектурные проблемы возникают при масштабировании WebSockets?

**Ответ:**  
Основные сложности:
- соединения stateful и долгоживущие
- клиент «привязан» к конкретному инстансу
- требуется sticky sessions или shared state
- сложнее горизонтально масштабировать

Практические последствия:
- нагрузка на memory и file descriptors
- сложная балансировка
- труднее делать rolling deploy

WebSockets оправданы только при настоящей необходимости двустороннего real-time взаимодействия.

---

## Server-Sent Events (SSE)

**Кратко:**  
SSE — односторонний streaming поверх HTTP.

**Типовой вопрос:**  
Когда SSE лучше WebSockets?

**Ответ:**  
Когда:
- сервер → клиент
- не нужен bidirectional
- важна простота масштабирования

SSE хорошо работает через обычные прокси.

---

## Long Polling

**Кратко:**  
Long polling — legacy-паттерн.

**Типовой вопрос:**  
Почему его стараются избегать?

**Ответ:**  
Потому что:
- держит соединения
- плохо масштабируется
- сложен под нагрузкой

Используется только при ограничениях.

---

## Idempotency

**Кратко:**  
Идемпотентность — свойство операции, при котором повторное выполнение запроса **не изменяет итоговое состояние системы**.  
Это базовое требование для надёжных распределённых систем.

**Типовой вопрос:**  
Почему идемпотентность критична при сетевых сбоях и retries?

**Ответ:**  
Сеть ненадёжна: запрос может выполниться, но ответ потеряться.  
Клиент повторяет запрос, не зная, был ли он обработан.

Если операция **не идемпотентна**:
- создаются дубликаты сущностей
- нарушаются бизнес-инварианты
- возможны финансовые ошибки (double charge, double order)

Типичные решения:
- идемпотентные HTTP-методы (`GET`, `PUT`, `DELETE`)
- idempotency key для `POST`
- дедупликация на стороне сервера

Идемпотентность — ответственность сервера, а не клиента.

---

## Timeouts

**Кратко:**  
Timeout — это жёсткое ограничение времени ожидания ответа, необходимое для защиты ресурсов системы.

**Типовой вопрос:**  
Почему отсутствие timeout опаснее, чем преждевременный отказ?

**Ответ:**  
Без timeout:
- соединения остаются открытыми
- треды / корутины блокируются
- ресурсы постепенно исчерпываются

В распределённых системах это приводит к:
- росту latency
- отказам по цепочке
- деградации всего сервиса

Практика:
- timeout должен быть на каждом сетевом вызове
- значения зависят от критичности операции
- клиентский timeout защищает сервер не меньше, чем клиента

---

## Rate Limiting

**Кратко:**  
Rate limiting — защита от abuse и ошибок клиентов.

**Типовой вопрос:**  
Почему rate limit нужен даже для internal API?

**Ответ:**  
Потому что:
- баги случаются
- сервисы могут DDoS друг друга
- защита инвариантов важнее доверия

---

## Load Balancing

**Кратко:**  
Load Balancing — это механизм распределения входящего трафика между несколькими инстансами сервиса с целью **устойчивости, масштабирования и снижения latency**. 

**Типовой вопрос:**  
Почему простые алгоритмы балансировки (например, round-robin) часто дают плохие результаты в продакшене?

**Ответ:**  
Round-robin распределяет запросы равномерно, но **игнорирует реальное состояние инстансов**:
- не учитывает текущую нагрузку (CPU, memory, I/O)
- не учитывает разницу в latency между инстансами
- не учитывает «прогрев» после деплоя или рестарта
- не реагирует на деградацию, пока инстанс формально жив

Более практичные подходы:
- **least connections**
- **latency-aware balancing**
- health checks + slow start
- adaptive load balancing (service mesh)

---

## Service Discovery

**Кратко:**  
Service discovery — это механизм динамического обнаружения сетевых адресов сервисов в распределённой системе.  
Без него невозможны auto-scaling и гибкий деплой.

**Типовой вопрос:**  
Почему жёстко прописанные адреса сервисов считаются архитектурной ошибкой?

**Ответ:**  
В современных системах:
- сервисы масштабируются динамически
- инстансы пересоздаются
- IP и порты меняются при каждом деплое

Hardcoded URLs приводят к тому, что:
- деплой одного сервиса ломает другие
- невозможно автоматическое масштабирование
- растёт операционная сложность

Типовые решения:
- **DNS-based discovery** (Kubernetes Services)
- **Service registry** (Consul, etcd)
- встроенный discovery в orchestration-платформах

---

## Observability в сетевом взаимодействии

**Кратко:**  
Observability — это способность понять, **что происходит в системе по внешним сигналам**, а не просто факт ошибки.  

**Типовой вопрос:**  
Почему логов недостаточно для анализа сетевых проблем?

**Ответ:**  
Логи:
- фрагментированы по сервисам
- плохо показывают временные зависимости
- не отражают картину целиком

Для сетевых вызовов критично отслеживать:
- **latency** (особенно p95 / p99)
- **error rate** по типам ошибок
- **timeouts**
- **retries и circuit breaker events**

Практика:
- метрики важнее логов
- трассировка (distributed tracing) обязательна
- latency важнее среднего значения

